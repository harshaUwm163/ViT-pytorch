{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *\n",
    "from addict import Dict\n",
    "import logging\n",
    "from utils.construct_tff import construct_real_tff\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.data_utils import get_loader\n",
    "!export CUDA_VISIBLE_DEVICES=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Dict()\n",
    "args.model_type = 'ViT-B_16'\n",
    "args.img_size = 224\n",
    "args.pretrained_dir = 'checkpoint/ViT-B_16.npz'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.device = device\n",
    "args.local_rank = -1\n",
    "args.train_batch_size = 128 \n",
    "args.eval_batch_size = 128\n",
    "\n",
    "# args.dataset = 'inet1k_cats'\n",
    "# args.dataset_dir = 'data/inet1k_classes/cats'\n",
    "# ckpt_path = 'output/inet1k_cats-2023-10-02-22-19-15/inet1k_cats_final_ckpt.bin' \n",
    "# args.dataset = 'inet1k_birds'\n",
    "# args.dataset_dir = 'data/inet1k_classes/birds'\n",
    "# ckpt_path = 'output/inet1k_birds-2023-10-02-22-25-22/inet1k_birds_final_ckpt.bin'\n",
    "# args.dataset = 'inet1k_dogs'\n",
    "# args.dataset_dir = 'data/inet1k_classes/dogs'\n",
    "# ckpt_path = 'output/inet1k_dogs-2023-09-24-21-00-17/inet1k_dogs_final_ckpt.bin'\n",
    "# args.dataset = 'inet1k_snakes'\n",
    "# args.dataset_dir = 'data/inet1k_classes/snakes'\n",
    "# ckpt_path = 'output/inet1k_snakes-2023-10-02-22-28-06/inet1k_snakes_final_ckpt.bin'\n",
    "args.dataset = 'inet1k_trucks'\n",
    "args.dataset_dir = 'data/inet1k_classes/trucks'\n",
    "ckpt_path = 'output/inet1k_trucks-2023-09-24-20-47-28/inet1k_trucks_final_ckpt.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_attn = 6144*2*2*2\n",
    "l_attn = 2\n",
    "n_attn = 768\n",
    "tffs = construct_real_tff(k_attn, l_attn // 2, n_attn // 2).to(args.device)\n",
    "frame_cat = tffs.view(-1, n_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redundancy = k_attn/384\n",
    "redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  0.9 0.8 0.5 0.2]\n",
      "[0.  0.1 0.2 0.5 0.8]\n"
     ]
    }
   ],
   "source": [
    "# percent of frames to keep\n",
    "frame_percents = np.array([1, 0.9, 0.8, 0.5, 0.2])\n",
    "frame_drops = 1 - frame_percents\n",
    "print(frame_percents)\n",
    "print(frame_drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.80327\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 39.43 GiB of which 14.31 MiB is free. Process 1602059 has 882.00 MiB memory in use. Process 1609780 has 1.53 GiB memory in use. Process 1610888 has 1.53 GiB memory in use. Process 1611212 has 1.53 GiB memory in use. Process 1611441 has 1.52 GiB memory in use. Process 1611702 has 1.52 GiB memory in use. Including non-PyTorch memory, this process has 30.93 GiB memory in use. Of the allocated memory 29.19 GiB is allocated by PyTorch, and 71.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/data/harsha/ViT-pytorch/frame_analysis_highSample.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bolvi1/data/harsha/ViT-pytorch/frame_analysis_highSample.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m itr \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_itrs):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bolvi1/data/harsha/ViT-pytorch/frame_analysis_highSample.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     args, model \u001b[39m=\u001b[39m setup(args)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bolvi1/data/harsha/ViT-pytorch/frame_analysis_highSample.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(ckpt_path))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bolvi1/data/harsha/ViT-pytorch/frame_analysis_highSample.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     norm_percent \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bolvi1/data/harsha/ViT-pytorch/frame_analysis_highSample.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     weight_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/bnetff/lib/python3.11/site-packages/torch/serialization.py:1006\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1005\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1006\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[1;32m   1007\u001b[0m                      map_location,\n\u001b[1;32m   1008\u001b[0m                      pickle_module,\n\u001b[1;32m   1009\u001b[0m                      overall_storage\u001b[39m=\u001b[39;49moverall_storage,\n\u001b[1;32m   1010\u001b[0m                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m   1011\u001b[0m \u001b[39mif\u001b[39;00m mmap:\n\u001b[1;32m   1012\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmmap can only be used with files saved with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1013\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1014\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bnetff/lib/python3.11/site-packages/torch/serialization.py:1414\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1412\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1413\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1414\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1416\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1417\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1418\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtorch.load.metadata\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mserialization_id\u001b[39m\u001b[39m\"\u001b[39m: zip_file\u001b[39m.\u001b[39mserialization_id()}\n\u001b[1;32m   1419\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/bnetff/lib/python3.11/site-packages/torch/serialization.py:1384\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1383\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1384\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1386\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/bnetff/lib/python3.11/site-packages/torch/serialization.py:1358\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1353\u001b[0m         storage\u001b[39m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1355\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1358\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1359\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1360\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1362\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1363\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/bnetff/lib/python3.11/site-packages/torch/serialization.py:373\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    372\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 373\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    374\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/bnetff/lib/python3.11/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mUntypedStorage(obj\u001b[39m.\u001b[39mnbytes(), device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(location))\n\u001b[1;32m    270\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39;49mcuda(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/bnetff/lib/python3.11/site-packages/torch/_utils.py:115\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m new_type(indices, values, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     untyped_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mUntypedStorage(\n\u001b[1;32m    116\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize(), device\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    118\u001b[0m     untyped_storage\u001b[39m.\u001b[39mcopy_(\u001b[39mself\u001b[39m, non_blocking)\n\u001b[1;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 39.43 GiB of which 14.31 MiB is free. Process 1602059 has 882.00 MiB memory in use. Process 1609780 has 1.53 GiB memory in use. Process 1610888 has 1.53 GiB memory in use. Process 1611212 has 1.53 GiB memory in use. Process 1611441 has 1.52 GiB memory in use. Process 1611702 has 1.52 GiB memory in use. Including non-PyTorch memory, this process has 30.93 GiB memory in use. Of the allocated memory 29.19 GiB is allocated by PyTorch, and 71.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "num_itrs = 10\n",
    "val_accs = []\n",
    "norm_percents = []\n",
    "for frame_percent in frame_percents:\n",
    "    frames_count = int(frame_percent * k_attn)\n",
    "\n",
    "    val_acc_i = 0\n",
    "    norm_percent_i = 0\n",
    "    for itr in range(num_itrs):\n",
    "        args, model = setup(args)\n",
    "        model.load_state_dict(torch.load(ckpt_path))\n",
    "        norm_percent = 0\n",
    "        weight_count = 0\n",
    "        for (name, param) in model.named_parameters():\n",
    "            if 'attn' in name:\n",
    "                if 'weight' in name:\n",
    "                    # U, S, Vh = torch.linalg.svd(param)\n",
    "                    # RotMat = U @ frame_cat\n",
    "                    # new_projs = torch.matmul(tffs, RotMat.transpose(0,1) ) @ param\n",
    "                    # new_norms = torch.norm(new_projs, dim=(1,2))\n",
    "                    # new_norms_sorted, indices = torch.sort(new_norms, descending=True)\n",
    "                    # norm_percent += torch.sqrt((new_norms_sorted[:frames_count]**2).sum()/(new_norms**2).sum())\n",
    "                    # weight_count += 1\n",
    "\n",
    "                    indices = torch.randperm(k_attn)\n",
    "                    new_frames_filtered = tffs[indices[:frames_count]].view(-1,n_attn)\n",
    "                    new_proj_mat = new_frames_filtered.transpose(0,1) @ new_frames_filtered\n",
    "\n",
    "                    new_projs = torch.matmul(new_frames_filtered, param)\n",
    "                    norm_percent += (torch.norm(new_projs) / torch.norm(param))**2\n",
    "                    weight_count += 1\n",
    "\n",
    "                    param.data = new_proj_mat @ param.data \n",
    "\n",
    "        # norm_percents.append(norm_percent.item() /(weight_count))\n",
    "        val_acc_i += valid(args, model, writer=None, test_loader=test_loader, global_step=0)\n",
    "        norm_percent_i += norm_percent.item()/weight_count\n",
    "    val_accs.append(val_acc_i/num_itrs)\n",
    "    norm_percents.append(norm_percent_i/num_itrs)\n",
    "\n",
    "    # print(f'{frame_percent = }, norm_percent = {norm_percents[-1]} {val_accs[-1] = }')\n",
    "    print(f'{frame_percent = } {val_accs[-1] = }')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(frame_percents, val_accs)\n",
    "plt.title(f'Val Accuracy Vs % frames used on {args.dataset}')\n",
    "plt.xlabel(f'% of Frames used')\n",
    "plt.ylabel(f'Validation Accuracy')\n",
    "plt.savefig(f'{args.dataset}_val_vs_frames.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(frame_percents, norm_percents)\n",
    "plt.title(f'% Norm retained Vs % frames used on {args.dataset}')\n",
    "plt.xlabel(f'% of Frames used')\n",
    "plt.ylabel(f'avg % of norm retained')\n",
    "plt.savefig(f'{args.dataset}_norm_vs_frames.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(norm_percents, val_accs)\n",
    "plt.title(f'Val accuracy Vs % Norm retained on {args.dataset}')\n",
    "plt.xlabel(f'avg % of norm retained')\n",
    "plt.ylabel(f'Validation accuracy')\n",
    "plt.savefig(f'{args.dataset}_Val_vs_norm.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnetff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
